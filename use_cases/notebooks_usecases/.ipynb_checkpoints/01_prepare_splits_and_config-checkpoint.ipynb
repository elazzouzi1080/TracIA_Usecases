{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd63c1db-59a1-47df-8632-e41970a32c07",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 01 — Data Preparation, Fixed Splits & Configuration\n",
    "\n",
    "**Goal**  \n",
    "In this step, we created *reusable, fixed* cross-validation splits on the original dataset.  \n",
    "The splits are saved to disk in `data/splits_dir/` together with a `manifest.json`.\n",
    "\n",
    "By fixing the splits once, we ensure that all future experiments (e.g., with tattooed/watermarked, anonymized, or synthetic datasets) can be evaluated under the exact same conditions.  \n",
    "This guarantees that results remain **fair and directly comparable** across dataset versions.\n",
    "\n",
    "> **We run this notebook.** Partners will need:\n",
    "\n",
    "- The `splits_dir/manifest.json` containing the following components:  \n",
    ">   - name: \"Fixed Stratified K-Fold Splits\"  \n",
    ">   - k  \n",
    ">   - random_state  \n",
    ">   - target  \n",
    ">   - features  \n",
    ">   - rows  \n",
    ">   - splits  \n",
    "> - The original **Heart Failure Clinical Records** dataset augmented with `row_id` to ensure reproducibility.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42726511",
   "metadata": {},
   "source": [
    "## 1) Configuration\n",
    "\n",
    "- `data_csv` — path to the original dataset (e.g., *Heart Failure Clinical Records*, Chicco & Jurman, 2020).\n",
    "- `features` — columns used as inputs.\n",
    "- `target` — the binary target column.\n",
    "- `k` — number of folds, with `shuffle=True` and fixed `random_state` to freeze splits.\n",
    "- `splits_dir` — where split CSVs and `manifest.json` will be written.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4091c2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits will be saved to: /donnees/home/elazzouzi/TracIA/use_cases/data/splits_k5_v1\n"
     ]
    }
   ],
   "source": [
    "# --- User config ---\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Path to ORIGINAL dataset  \n",
    "data_csv = Path(\"../data/heart_failure_clinical_records_dataset.csv\") \n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(data_csv)\n",
    "\n",
    "# Baseline features & target  \n",
    "\n",
    "target = \"DEATH_EVENT\"\n",
    "# Use all features except the target\n",
    "features = [col for col in df.columns if col != target]\n",
    "\n",
    "# Cross‑validation setup\n",
    "k = 5\n",
    "random_state = 42\n",
    "\n",
    "# Where to save the fixed splits + manifest\n",
    "splits_dir = Path(\"../data/splits_k5_v1\")   \n",
    "splits_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Splits will be saved to: {splits_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a865941e",
   "metadata": {},
   "source": [
    "## 2) Load data and add a stable `row_id`\n",
    "\n",
    "We attach a `row_id` column (0..N-1) **once** on the original dataset. All transformed datasets MUST preserve this\n",
    "`row_id` so splits remain valid and rows can be matched exactly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df039ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
      "0  75.0        0                       582         0                 20   \n",
      "1  55.0        0                      7861         0                 38   \n",
      "2  65.0        0                       146         0                 20   \n",
      "3  50.0        1                       111         0                 20   \n",
      "4  65.0        1                       160         1                 20   \n",
      "\n",
      "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
      "0                    1  265000.00               1.9           130    1   \n",
      "1                    0  263358.03               1.1           136    1   \n",
      "2                    0  162000.00               1.3           129    1   \n",
      "3                    0  210000.00               1.9           137    1   \n",
      "4                    0  327000.00               2.7           116    0   \n",
      "\n",
      "   smoking  time  DEATH_EVENT  row_id  \n",
      "0        0     4            1       0  \n",
      "1        0     6            1       1  \n",
      "2        1     7            1       2  \n",
      "3        0     7            1       3  \n",
      "4        0     8            1       4  \n",
      "Saved (owner‑only) copy with row_id to: ../data/splits_k5_v1/heart_failure_clinical_records_dataset_with_row_id.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_csv)\n",
    "assert target in df.columns, f\"Target column '{target}' not found in data.\"\n",
    "for col in features:\n",
    "    assert col in df.columns, f\"Feature column '{col}' not found in data.\"\n",
    "\n",
    "# Ensure a deterministic row_id  \n",
    "if 'row_id' not in df.columns:\n",
    "    df = df.reset_index(drop=True).copy()\n",
    "    df['row_id'] = df.index\n",
    "else:\n",
    "    # Enforce integer type\n",
    "    df['row_id'] = df['row_id'].astype(int)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Optional: save a clean copy with row_id (owner's internal reference)\n",
    "clean_with_ids = splits_dir / \"heart_failure_clinical_records_dataset_with_row_id.csv\"\n",
    "df.to_csv(clean_with_ids, index=False)\n",
    "print(f\"Saved (owner‑only) copy with row_id to: {clean_with_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a1df5c",
   "metadata": {},
   "source": [
    "## 3) Create *fixed* stratified K‑fold splits and write CSVs\n",
    "\n",
    "We store two CSV files **per fold**:\n",
    "- `train_ids_foldX.csv` — a single column `row_id` with training row IDs\n",
    "- `test_ids_foldX.csv` — a single column `row_id` with test row IDs\n",
    "\n",
    "A `manifest.json` documents the split files and basic metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d0fb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5 folds. Manifest written to: ../data/splits_k5_v1/manifest.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'fold': 1,\n",
       "  'train_file': 'train_ids_fold1.csv',\n",
       "  'test_file': 'test_ids_fold1.csv',\n",
       "  'n_train': 239,\n",
       "  'n_test': 60},\n",
       " {'fold': 2,\n",
       "  'train_file': 'train_ids_fold2.csv',\n",
       "  'test_file': 'test_ids_fold2.csv',\n",
       "  'n_train': 239,\n",
       "  'n_test': 60},\n",
       " {'fold': 3,\n",
       "  'train_file': 'train_ids_fold3.csv',\n",
       "  'test_file': 'test_ids_fold3.csv',\n",
       "  'n_train': 239,\n",
       "  'n_test': 60},\n",
       " {'fold': 4,\n",
       "  'train_file': 'train_ids_fold4.csv',\n",
       "  'test_file': 'test_ids_fold4.csv',\n",
       "  'n_train': 239,\n",
       "  'n_test': 60},\n",
       " {'fold': 5,\n",
       "  'train_file': 'train_ids_fold5.csv',\n",
       "  'test_file': 'test_ids_fold5.csv',\n",
       "  'n_train': 240,\n",
       "  'n_test': 59}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "splits_meta = []\n",
    "y = df[target].values\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(df, y), start=1):\n",
    "    train_ids = df.loc[train_idx, 'row_id'].to_frame()\n",
    "    test_ids  = df.loc[test_idx,  'row_id'].to_frame()\n",
    "\n",
    "    train_file = splits_dir / f\"train_ids_fold{fold}.csv\"\n",
    "    test_file  = splits_dir / f\"test_ids_fold{fold}.csv\"\n",
    "    train_ids.to_csv(train_file, index=False)\n",
    "    test_ids.to_csv(test_file, index=False)\n",
    "\n",
    "    splits_meta.append({\n",
    "        \"fold\": fold,\n",
    "        \"train_file\": train_file.name,\n",
    "        \"test_file\": test_file.name,\n",
    "        \"n_train\": int(len(train_ids)),\n",
    "        \"n_test\": int(len(test_ids))\n",
    "    })\n",
    "\n",
    "manifest = {\n",
    "    \"name\": \"Fixed Stratified K-Fold Splits\",\n",
    "    \"k\": k,\n",
    "    \"random_state\": random_state,\n",
    "    \"target\": target,\n",
    "    \"features\": features,\n",
    "    \"rows\": int(len(df)),\n",
    "    \"splits\": splits_meta\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(splits_dir / \"manifest.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(manifest, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Created {k} folds. Manifest written to: {splits_dir / 'manifest.json'}\")\n",
    "splits_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393b1cdd-f9d2-44c9-8def-430e60eb48a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TraceIA Use Cases)",
   "language": "python",
   "name": "traceia-uc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
