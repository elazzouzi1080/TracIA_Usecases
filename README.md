# ğŸ§ª TracIA Usecases â€” Pipeline ML (Heart Failure Dataset)

Ce dÃ©pÃ´t prÃ©sente un **pipeline reproductible** dâ€™expÃ©rimentation machine learning appliquÃ© Ã  un dataset mÃ©dical de rÃ©fÃ©rence : le *Heart Failure Clinical Records Dataset*.  
Lâ€™objectif est de fournir un exemple simple, transparent et traÃ§able pour comparer plusieurs modÃ¨les de classification binaire.

---

## âš™ï¸ Ã‰tape 1. Contexte gÃ©nÃ©ral
- **Projet** : dÃ©monstration de cas dâ€™usage pour le projet **TracIA** (traÃ§abilitÃ© & IA en santÃ©).  
- **But** : tester et comparer diffÃ©rents modÃ¨les de machine learning (LogReg, SVM, RF, MLP, etc.) dans un cadre reproductible.  
- **MÃ©thode clÃ©** : utilisation de *splits fixes* (5-fold cross-validation dÃ©terministe) afin que tous les partenaires puissent Ã©valuer leurs mÃ©thodes sur les **mÃªmes conditions de validation**.

---

## ğŸ“Š Ã‰tape 2. Dataset utilisÃ©

**Nom** : Heart Failure Clinical Records Dataset  
**Source** : [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records)  
**Taille** : 299 patients (105 femmes, 194 hommes), Ã¢ge 40â€“95 ans  
**Contexte** : patients suivis au Faisalabad Institute of Cardiology & Allied Hospital (Pakistan, 2015)  
**Cible** : `DEATH_EVENT` (0 = survie, 1 = dÃ©cÃ¨s)  

**Variables principales :**
- DonnÃ©es dÃ©mographiques : `age`, `sex`, `smoking`  
- Facteurs cliniques : `anaemia`, `diabetes`, `high_blood_pressure`  
- Examens biologiques : `serum_creatinine`, `serum_sodium`, `platelets`, `creatinine_phosphokinase`  
- Mesure cardiaque clÃ© : `ejection_fraction` (%)  
- DurÃ©e de suivi : `time` (jours)  

**Classes :**
- 203 survivants (â‰ˆ 68 %)  
- 96 dÃ©cÃ¨s (â‰ˆ 32 %)  

> âš ï¸ Dataset petit, monocentrique et dÃ©sÃ©quilibrÃ©, mais idÃ©al pour dÃ©monstration et benchmark.

---

## ğŸ“’ Ã‰tape 3. Notebook 1 â€” PrÃ©paration des splits et configuration
**Fichier** : `01_prepare_splits_and_config.ipynb`  

Ce notebook permet de :
- Charger le dataset brut  
- Ajouter un identifiant unique `row_id`  
- GÃ©nÃ©rer des **splits fixes stratifiÃ©s (k=5)** avec graine alÃ©atoire dÃ©terministe  
- Sauvegarder les fichiers nÃ©cessaires dans `data/splits_k5_v1/` :  
  - `manifest.json` (mÃ©tadonnÃ©es : cible, features, taille des splits, etc.)  
  - `train_ids_fold*.csv` et `test_ids_fold*.csv`  

> Ces splits seront rÃ©utilisÃ©s pour tous les entraÃ®nements afin dâ€™assurer la comparabilitÃ© des rÃ©sultats.

---

## ğŸ–¥ï¸ Ã‰tape 4. Script â€” ExÃ©cution du pipeline complet
**Fichier** : `fixed_cv_binary_classification.py`  

Ce script exÃ©cute automatiquement :
1. Chargement du dataset + splits fixes  
2. EntraÃ®nement de plusieurs modÃ¨les classiques (LogReg, SVM, RF, MLPâ€¦)  
3. Ã‰valuation sur chaque fold avec un ensemble de mÃ©triques :  
   - AUC-ROC, AUC-PR, MCC, Brier, ACC, F1, SE, SP, PPV, NPV  
4. Sauvegarde des rÃ©sultats dans `results_pipline/` :
   - RÃ©sultats par fold (`cv_results_per_fold.csv/json`)  
   - RÃ©sumÃ© global (`cv_results_summary.csv/json`)  
   - Excel complet (`cv_results_complete.xlsx`)  
   - Tests statistiques (Wilcoxon pairwise sur AUC-ROC)  
   - Figures de comparaison (`figures/model_comparison_*.png`)  

---

## ğŸ“’ Ã‰tape 5. Notebook 2 â€” ExÃ©cution interactive
**Fichier** : `02_run_binary_classification_pipeline.ipynb`  

Ce notebook reprend les Ã©tapes du script mais en version **pas-Ã -pas** et interactive, permettant de :
- Explorer les splits et vÃ©rifier les donnÃ©es  
- Lancer manuellement lâ€™entraÃ®nement des modÃ¨les  
- Visualiser les rÃ©sultats et figures dans Jupyter  

---

## ğŸ“‚ Ã‰tape 6. Arborescence du dÃ©pÃ´t
```
use_cases/
â”œâ”€ data/
â”‚  â”œâ”€ heart_failure_clinical_records_dataset.csv
â”‚  â””â”€ splits_k5_v1/
â”‚     â”œâ”€ manifest.json
â”‚     â”œâ”€ train_ids_fold*.csv
â”‚     â””â”€ test_ids_fold*.csv
â”œâ”€ notebooks_usecases/
â”‚  â”œâ”€ fixed_cv_binary_classification.py
â”‚  â”œâ”€ 01_prepare_splits_and_config.ipynb
â”‚  â”œâ”€ 02_run_binary_classification_pipeline.ipynb
â”‚  â””â”€ requirements.txt
â””â”€ results_pipline/
   â”œâ”€ cv_results_per_fold.*
   â”œâ”€ cv_results_summary.*
   â”œâ”€ cv_results_complete.xlsx
   â”œâ”€ statistical_tests.csv
   â””â”€ figures/
```

---

## ğŸš€ Ã‰tape 7. Installation & lancement
```bash
# Cloner le dÃ©pÃ´t
git clone https://github.com/elazzouzi1080/TracIA_Usecases.git
cd TracIA_Usecases/use_cases/notebooks_usecases

# CrÃ©er un venv (optionnel)
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# Installer dÃ©pendances
pip install -r requirements.txt

# Lancer le pipeline complet
python fixed_cv_binary_classification.py
```
