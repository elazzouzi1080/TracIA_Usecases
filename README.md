# ğŸ§ª Binary Classification Pipeline with Fixed Cross-Validation

A robust, reproducible machine learning pipeline for binary classification tasks using stratified k-fold cross-validation with fixed splits.
 
---
To enable all partners to work under identical and comparable conditions, a complete experimental environment has been defined. This environment relies on a single dataset, fixed cross-validation splits, a centralized configuration file, and a reference classification pipeline.
---

## ğŸ“‹ Overview

This pipeline provides a complete framework for evaluating multiple baseline classifiers on binary classification datasets. It emphasizes **reproducibility** through fixed cross-validation splits and **comprehensive evaluation metrics**.

### Key Features
- âœ… **Fixed CV Splits**: Ensures reproducibility across experiments  
- âœ… **Multiple Baselines**: 9 pre-configured classifiers (LR, SVM, RF, etc.)  
- âœ… **Comprehensive Metrics**: 11 evaluation metrics including AUC-ROC, F1, MCC  
- âœ… **Rich Visualizations**: Box plots, ROC curves, confidence intervals  
- âœ… **Multiple Export Formats**: CSV, JSON, Excel with metadata  

---

## ğŸ—‚ï¸ Project Structure

```
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_prepare_splits_and_config.ipynb      # One-time split creation
â”‚   â””â”€â”€ 02_run_binary_classification_pipeline.ipynb  # Main evaluation
â”‚   â””â”€â”€ fixed_cv_binary_classification.py       # Core pipeline code
â”œâ”€â”€ data/
â”‚   â””â”€â”€ splits_k5_v1/
â”‚       â”œâ”€â”€ manifest.json                       # Split metadata
â”‚       â”œâ”€â”€ train_ids_fold*.csv                 # Training row IDs
â”‚       â”œâ”€â”€ test_ids_fold*.csv                  # Test row IDs
â”‚       â””â”€â”€ heart_failure_..._with_row_id.csv   # Dataset + row_id
â””â”€â”€ results_pipeline/
    â”œâ”€â”€ cv_results_per_fold.csv                 # Detailed results
    â”œâ”€â”€ cv_results_summary.csv                  # Aggregated statistics
    â”œâ”€â”€ cv_results_complete.xlsx                # Multi-sheet workbook
    â”œâ”€â”€ statistical_tests.csv                   # Pairwise comparisons
    â””â”€â”€ figures/                                # Visualizations
```

---
## ğŸ“Š Dataset

**Nom** : Heart Failure Clinical Records Dataset  
**Source** : [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records)  
**Taille** : 299 patients (105 femmes, 194 hommes), Ã¢ge 40â€“95 ans  
**Contexte** : patients suivis au Faisalabad Institute of Cardiology & Allied Hospital (Pakistan, 2015)  
**Cible** : `DEATH_EVENT` (0 = survie, 1 = dÃ©cÃ¨s)  

**Variables principales :**
- DonnÃ©es dÃ©mographiques : `age`, `sex`, `smoking`  
- Facteurs cliniques : `anaemia`, `diabetes`, `high_blood_pressure`  
- Examens biologiques : `serum_creatinine`, `serum_sodium`, `platelets`, `creatinine_phosphokinase`  
- Mesure cardiaque clÃ© : `ejection_fraction` (%)  
- DurÃ©e de suivi : `time` (jours)  

**Classes :**
- 203 survivants (â‰ˆ 68 %)  
- 96 dÃ©cÃ¨s (â‰ˆ 32 %)  
---
## ğŸš€ Quick Start

### Prerequisites
```bash
pip install numpy pandas scikit-learn matplotlib seaborn tqdm scipy
```

## Step 1: Prepare Fixed Splits (One-Time Setup) âœ… *Already Done*  

The preparation of fixed splits has **already been executed**.  
You **do not need to re-run** `01_prepare_splits_and_config.ipynb`.
This notebook was used once to:
1. Load the dataset  
2. Add stable `row_id` column  
3. Create stratified k-fold splits  
4. Save splits and manifest  

ğŸ‘‰ Output: `data/splits_k5_v1/` with `manifest.json` and split files.

### Step 2: Run Evaluation Pipeline
```python
from fixed_cv_binary_classification import BinaryClassificationPipeline, Config

config = Config(
    splits_dir="data/splits_k5_v1/",
    dataset_csv="data/splits_k5_v1/heart_failure_..._with_row_id.csv",
    results_dir="results_pipeline",
    random_state=42
)

pipeline = BinaryClassificationPipeline(config)
results_df, summary_df = pipeline.run()
```

Or use the provided notebook: `02_run_binary_classification_pipeline.ipynb`

---

## ğŸ“Š Evaluated Models

| Model      | Description                  | Key Parameters |
|------------|------------------------------|----------------|
| LR         | Logistic Regression          | liblinear solver |
| SVM_linear | Linear SVM                   | class_weight='balanced' |
| SVM_rbf    | RBF kernel SVM               | gamma='scale' |
| kNN_k5     | k-Nearest Neighbors          | k=5, distance weights |
| DT         | Decision Tree                | max_depth=5 |
| RF         | Random Forest                | 100 trees, balanced |
| NB         | Gaussian Naive Bayes         | var_smoothing=1e-9 |
| GB         | Gradient Boosting            | 100 estimators, lr=0.1 |
| MLP        | Neural Network               | (100,50) layers |

---

## ğŸ“ˆ Evaluation Metrics

The pipeline computes **11 metrics**:

- Brier: Brier score (calibration)  
- BACC: Balanced accuracy  
- MCC: Matthews Correlation Coefficient  
- AUC_ROC: Area Under ROC Curve  
- AUC_PR: Area Under Precision-Recall Curve  
- SE: Sensitivity (Recall)  
- PPV: Positive Predictive Value (Precision)  
- F1: F1 Score  
- SP: Specificity  
- NPV: Negative Predictive Value  
- ACC: Accuracy  

---

## ğŸ”§ Configuration Options

```python
@dataclass
class Config:
    splits_dir: Path = Path("../data/splits_k5_v1/")
    dataset_csv: Path = Path("../data/splits_k5_v1/heart_failure_..._with_row_id.csv")
    results_dir: Path = Path("../results_pipeline")
    
    metrics_list: List[str] = ["Brier", "BACC", "MCC", ...]
    random_state: int = 42
    n_jobs: int = -1  # Parallel processing
    
    fig_size: Tuple[int, int] = (12, 8)
    dpi: int = 100
```

---

## ğŸ“¦ Output Files

### Results
- `cv_results_per_fold.csv`: Fold-by-fold metrics  
- `cv_results_summary.csv`: Mean, std, median, CI  
- `cv_results_complete.xlsx`: Multi-sheet workbook with metadata  

### Visualizations
- `model_comparison_AUC_ROC.png`: AUC-ROC scores across models
- `model_comparison_F1.png`: F1 scores across models
- `model_comparison_MCC.png`: MCC scores across models

### JSON
- `cv_results_per_fold.json`  
- `cv_results_summary.json`  

---

## ğŸ“ Example Results

```
================================================================================
TOP 5 MODELS BY AUC-ROC
================================================================================
     model      AUC_ROC_mean   AUC_ROC_std   F1_mean   MCC_mean
     RF         0.901355       0.026516      0.744379  0.639031
     GB         0.894490       0.012779      0.725710  0.603015
 SVM_linear     0.876203       0.033730      0.661672  0.542740
     LR         0.875163       0.031707      0.721311  0.607449
  SVM_rbf       0.860661       0.031572      0.678865  0.550067
================================================================================
```

---
